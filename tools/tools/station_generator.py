#!/usr/bin/env python3
"""
Station Code Generator

Generates complete, production-ready station code based on wizard inputs.
Creates adaptive code that follows the existing station patterns.
"""

from typing import Dict, Any, List
from datetime import datetime


class StationCodeGenerator:
    """Generates station code and configuration files"""

    def __init__(self, session_data: Dict[str, Any]):
        self.data = session_data
        self.station_num = session_data["station_number"]
        self.station_name = session_data["station_name"]
        self.file_name = session_data["file_name"]
        self.class_name = self._generate_class_name()

    def _generate_class_name(self) -> str:
        """Generate Python class name from station name"""
        # Convert "Music Cue Generator" to "MusicCueGenerator"
        words = self.station_name.split()
        return ''.join(word.capitalize() for word in words)

    def generate_station_code(self) -> str:
        """Generate complete Python code for the station"""

        # Get input loading code
        input_loading_code = self._generate_input_loading_code()

        # Get processing logic template
        processing_template = self._generate_processing_logic()

        code = f'''#!/usr/bin/env python3
"""
Station {self.station_num}: {self.station_name}

{self.data['station_purpose']}

Type: {self.data['station_type']}
Dependencies: {', '.join([f"Station {s['number']}" for s in self.data['input_stations']]) if self.data['input_stations'] else 'None'}

Auto-generated by Station Creator Wizard on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""

import asyncio
import json
import logging
import re
from datetime import datetime
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, asdict

from app.openrouter_agent import OpenRouterAgent
from app.redis_client import RedisClient
from app.agents.config_loader import load_station_config

# Configure logging
logger = logging.getLogger(__name__)


@dataclass
class Station{self.station_num:02d}Output:
    """Output structure for Station {self.station_num}"""
    session_id: str
    station_id: str
    timestamp: datetime
    data: Dict[str, Any]  # Main output data
    metadata: Dict[str, Any]  # Additional metadata


class Station{self.station_num:02d}{self.class_name}:
    """
    Station {self.station_num}: {self.station_name}

    {self.data['station_purpose']}
    """

    def __init__(self):
        self.openrouter = OpenRouterAgent()
        self.redis = RedisClient()
        self.station_id = "station_{self.station_num:02d}"

        # Load station configuration from YAML
        self.config = load_station_config(station_number={self.station_num})

        # Get prompt template from config
        self.prompt_template = self.config.get_prompt('main')

    async def initialize(self):
        """Initialize the station"""
        await self.redis.initialize()
        logger.info(f"Station {self.station_num}: {{self.__class__.__name__}} initialized")

    async def process(self, session_id: str) -> Station{self.station_num:02d}Output:
        """
        Main processing method for Station {self.station_num}

        Args:
            session_id: Unique session identifier

        Returns:
            Station{self.station_num:02d}Output: Complete output from this station
        """
        try:
            logger.info(f"Station {self.station_num} processing started for session {{session_id}}")

            # Gather inputs from previous stations
            inputs = await self._gather_inputs(session_id)

            # Process with AI using retry logic
            result_data = await self._process_with_ai(inputs, session_id)

            # Create output structure
            output = Station{self.station_num:02d}Output(
                session_id=session_id,
                station_id=self.station_id,
                timestamp=datetime.utcnow(),
                data=result_data,
                metadata={{
                    "station_name": "{self.station_name}",
                    "station_type": "{self.data['station_type']}",
                    "ai_model": self.config.model,
                    "input_stations": [{', '.join([str(s['number']) for s in self.data['input_stations']])}]
                }}
            )

            # Store output in Redis
            await self._store_output(session_id, output)

            logger.info(f"Station {self.station_num} completed successfully for session {{session_id}}")
            return output

        except Exception as e:
            logger.error(f"Station {self.station_num} processing failed for session {{session_id}}: {{str(e)}}")
            raise

    async def _gather_inputs(self, session_id: str) -> Dict[str, Any]:
        """Gather inputs from previous stations"""
        logger.info(f"Gathering inputs from previous stations")

        inputs = {{
            "session_id": session_id,
            "timestamp": datetime.utcnow().isoformat()
        }}

{input_loading_code}

        return inputs

    async def _process_with_ai(self, inputs: Dict[str, Any], session_id: str) -> Dict[str, Any]:
        """Process inputs using AI with retry logic"""

        max_retries = 5
        retry_delay = 3  # seconds

        for attempt in range(max_retries):
            try:
                if attempt > 0:
                    logger.info(f"Retry attempt {{attempt + 1}}/{{max_retries}} for Station {self.station_num}")
                    await asyncio.sleep(retry_delay * attempt)

                # Format prompt with inputs
                formatted_prompt = self._format_prompt(inputs)

                # Get LLM response
                response = await self.openrouter.process_message(
                    formatted_prompt,
                    model_name=self.config.model
                )

                # Parse response into structured data
                parsed_data = self._parse_ai_response(response)

                logger.info(f"✅ Station {self.station_num} AI processing succeeded on attempt {{attempt + 1}}")
                return parsed_data

            except Exception as e:
                logger.warning(f"⚠️ Station {self.station_num} attempt {{attempt + 1}}/{{max_retries}} failed: {{str(e)}}")
                if attempt == max_retries - 1:
                    logger.error(f"❌ Station {self.station_num} FAILED after {{max_retries}} attempts")
                    raise ValueError(f"Station {self.station_num} failed after {{max_retries}} retries: {{str(e)}}")

    def _format_prompt(self, inputs: Dict[str, Any]) -> str:
        """Format the AI prompt with input data"""

{processing_template}

        return formatted_prompt

    def _parse_ai_response(self, response: str) -> Dict[str, Any]:
        """Parse AI response into structured format"""

        try:
            # Try to parse as JSON first
            if "{{" in response and "}}" in response:
                # Extract JSON from response
                json_match = re.search(r'\\{{.*\\}}', response, re.DOTALL)
                if json_match:
                    return json.loads(json_match.group(0))

            # If not JSON, create structured output from text
            return {{
                "raw_response": response,
                "parsed_at": datetime.utcnow().isoformat(),
                "format": "text"
            }}

        except Exception as e:
            logger.warning(f"Failed to parse AI response as JSON: {{str(e)}}")
            return {{
                "raw_response": response,
                "error": str(e),
                "parsed_at": datetime.utcnow().isoformat()
            }}

    async def _store_output(self, session_id: str, output: Station{self.station_num:02d}Output) -> None:
        """Store output in Redis for next station"""
        try:
            # Convert to dictionary for JSON serialization
            output_dict = {{
                "station_id": output.station_id,
                "session_id": output.session_id,
                "timestamp": output.timestamp.isoformat(),
                "data": output.data,
                "metadata": output.metadata
            }}

            # Store in Redis with session-based key
            key = f"audiobook:{{session_id}}:station_{self.station_num:02d}"
            await self.redis.set(key, json.dumps(output_dict), expire=86400)  # 24 hour expiry

            logger.info(f"Station {self.station_num} output stored successfully for session {{session_id}}")

        except Exception as e:
            logger.error(f"Failed to store Station {self.station_num} output: {{str(e)}}")
            raise

    async def get_stored_output(self, session_id: str) -> Optional[Station{self.station_num:02d}Output]:
        """Retrieve stored output for a session"""
        try:
            key = f"audiobook:{{session_id}}:station_{self.station_num:02d}"
            stored_data = await self.redis.get(key)

            if not stored_data:
                return None

            data = json.loads(stored_data)

            return Station{self.station_num:02d}Output(
                session_id=data["session_id"],
                station_id=data["station_id"],
                timestamp=datetime.fromisoformat(data["timestamp"]),
                data=data["data"],
                metadata=data["metadata"]
            )

        except Exception as e:
            logger.error(f"Failed to retrieve Station {self.station_num} output: {{str(e)}}")
            return None

    def export_to_dict(self, output: Station{self.station_num:02d}Output) -> Dict[str, Any]:
        """Export output to dictionary format"""
        return {{
            "station_id": output.station_id,
            "station_name": "{self.station_name}",
            "session_id": output.session_id,
            "timestamp": output.timestamp.isoformat(),
            "data": output.data,
            "metadata": output.metadata
        }}
'''

        return code

    def _generate_input_loading_code(self) -> str:
        """Generate code to load inputs from previous stations"""

        if not self.data['input_stations']:
            return '''        # No inputs from previous stations required
        logger.info("This station operates independently")'''

        code_lines = []
        for station in self.data['input_stations']:
            code_lines.append(f'''        # Load data from Station {station['number']}: {station['name']}
        try:
            station_{station['number']}_key = f"audiobook:{{session_id}}:station_{station['number']:02d}"
            station_{station['number']}_data = await self.redis.get(station_{station['number']}_key)
            if station_{station['number']}_data:
                inputs['station_{station['number']}'] = json.loads(station_{station['number']}_data)
                logger.info(f"Loaded data from Station {station['number']}: {station['name']}")
            else:
                logger.warning(f"No data found from Station {station['number']}")
        except Exception as e:
            logger.error(f"Failed to load Station {station['number']} data: {{str(e)}}")
''')

        return '\n'.join(code_lines)

    def _generate_processing_logic(self) -> str:
        """Generate the prompt formatting logic"""

        # Create a simple template that uses the configured prompt
        return f'''        # Use the prompt template from configuration
        # The prompt template contains: {self.data['ai_prompt'][:100]}...

        # Format with available inputs
        try:
            formatted_prompt = self.prompt_template.format(**inputs)
        except KeyError:
            # If template formatting fails, use inputs as context
            formatted_prompt = f"""
{{self.prompt_template}}

CONTEXT DATA:
{{json.dumps(inputs, indent=2)}}
"""'''

    def generate_yaml_config(self) -> str:
        """Generate YAML configuration file"""

        yaml_content = f'''# Station {self.station_num}: {self.station_name} Configuration

model: "{self.data['ai_model']}"
temperature: 0.7
max_tokens: 4000

prompts:
  main: |
{self._indent_text(self.data['ai_prompt'], 4)}

# Expected output format
output_format: |
{self._indent_text(self.data['output_format'], 2)}

# Station metadata
metadata:
  station_number: {self.station_num}
  station_name: "{self.station_name}"
  station_type: "{self.data['station_type']}"
  purpose: "{self.data['station_purpose']}"
  created: "{datetime.now().isoformat()}"
  created_by: "Station Creator Wizard"

# Input dependencies
dependencies:
{self._format_dependencies()}

# Processing settings
settings:
  retry_attempts: 5
  retry_delay: 3
  timeout: 120
  enable_caching: true

# Enable/disable this station in the pipeline
enabled: true
'''

        return yaml_content

    def _indent_text(self, text: str, spaces: int) -> str:
        """Indent text by specified number of spaces"""
        indent = ' ' * spaces
        lines = text.split('\n')
        return '\n'.join(indent + line if line.strip() else '' for line in lines)

    def _format_dependencies(self) -> str:
        """Format dependency list for YAML"""
        if not self.data['input_stations']:
            return '  none: true'

        deps = []
        for station in self.data['input_stations']:
            deps.append(f'  - station: {station["number"]}')
            deps.append(f'    name: "{station["name"]}"')
            if 'description' in station:
                deps.append(f'    description: "{station["description"]}"')

        return '\n'.join(deps)
